{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMclrySp7r4GJty3zjarawo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RayhanNuansa/Komputasi_Intelegensia/blob/main/TaskWeek7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nama : Muhammad Rayhan Nuansa Adha\n",
        "\n",
        "NPM : 2006571053\n",
        "\n",
        "Model : https://huggingface.co/ayameRushia/roberta-base-indonesian-1.5G-sentiment-analysis-smsa"
      ],
      "metadata": {
        "id": "lRasS7_xowH7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkdBlSCqot3K",
        "outputId": "bd67cee2-40b1-4c88-8639-ef3b6b46884c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\n",
        "\"text-classification\",\n",
        "model=\"ayameRushia/roberta-base-indonesian-1.5G-sentiment-analysis-smsa\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset kalimat-kalimat synthetic untuk sentiment analysis\n",
        "synthetic_dataset = [\n",
        "    {\"text\": \"Hari ini benar-benar menyenangkan, aku merasa sangat bahagia!\", \"label\": \"POSITIVE\"},\n",
        "    {\"text\": \"Pelayanannya sangat memuaskan, saya pasti akan kembali lagi.\", \"label\": \"POSITIVE\"},\n",
        "    {\"text\": \"Makanan di restoran ini lezat sekali, benar-benar direkomendasikan.\", \"label\": \"POSITIVE\"},\n",
        "    {\"text\": \"Pengalaman belanja di toko ini selalu memuaskan.\", \"label\": \"POSITIVE\"},\n",
        "    {\"text\": \"Film itu luar biasa, saya sangat menikmatinya!\", \"label\": \"POSITIVE\"},\n",
        "\n",
        "    {\"text\": \"Aku baru saja pergi ke kantor pos untuk mengirim paket.\", \"label\": \"NEUTRAL\"},\n",
        "    {\"text\": \"Cuaca hari ini cukup cerah, cocok untuk berjalan-jalan.\", \"label\": \"NEUTRAL\"},\n",
        "    {\"text\": \"Perjalanan ke kantor memakan waktu sekitar 30 menit.\", \"label\": \"NEUTRAL\"},\n",
        "    {\"text\": \"Dia sedang duduk di taman, membaca buku.\", \"label\": \"NEUTRAL\"},\n",
        "    {\"text\": \"Aku menonton televisi selama beberapa jam.\", \"label\": \"NEUTRAL\"},\n",
        "\n",
        "    {\"text\": \"Makanan di restoran ini sangat hambar, tidak enak sama sekali.\", \"label\": \"NEGATIVE\"},\n",
        "    {\"text\": \"Pengalaman belanja di tempat ini sungguh mengecewakan.\", \"label\": \"NEGATIVE\"},\n",
        "    {\"text\": \"Filmnya membosankan, aku menyesal telah menontonnya.\", \"label\": \"NEGATIVE\"},\n",
        "    {\"text\": \"Pelayanannya buruk sekali, tidak profesional.\", \"label\": \"NEGATIVE\"},\n",
        "    {\"text\": \"Saya tidak akan kembali lagi ke sini, kualitasnya benar-benar di bawah standar.\", \"label\": \"NEGATIVE\"}\n",
        "]"
      ],
      "metadata": {
        "id": "jv5DpV6ayqkY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan prediksi dan menyimpan hasil prediksi\n",
        "true_labels = [item[\"label\"] for item in synthetic_dataset]\n",
        "predicted_labels = []\n",
        "\n",
        "for item in synthetic_dataset:\n",
        "    prediction = pipe(item[\"text\"])[0]\n",
        "    predicted_labels.append(prediction['label'].upper())"
      ],
      "metadata": {
        "id": "YQwqOKlNzcB6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Menghitung akurasi\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(f\"Akurasi: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTsKyGdQzeiH",
        "outputId": "24874298-50ff-410b-9940-8e1fc9d649df"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi: 93.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Self-attention adalah komponen utama dalam semua model Transformer, termasuk ROBERTA, BERT, dan varian lainnya, yang digunakan untuk memahami konteks kata dalam suatu kalimat berdasarkan seluruh kalimat tersebut.\n",
        "\n",
        "Terkait pengimplementasian attention transformer pada model tersebut tidak dapat dilakukan karena model \"ayameRushia/roberta-base-indonesian-1.5G-sentiment-analysis-smsa\" yang digunakan adalah model berbasis Transformer (ROBERTA) yang sudah menggunakan mekanisme self-attention di dalam arsitekturnya."
      ],
      "metadata": {
        "id": "qOw6MjGD3K81"
      }
    }
  ]
}